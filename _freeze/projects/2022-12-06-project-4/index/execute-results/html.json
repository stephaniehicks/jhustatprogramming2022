{
  "hash": "92e04c96b90e34da647999dc6f5bb55c",
  "result": {
    "markdown": "---\ntitle: \"Project 4\"\nauthor: \n  - name: Stephanie Hicks\n    url: https://stephaniehicks.com\n    affiliation: Department of Biostatistics, Johns Hopkins\n    affiliation_url: https://publichealth.jhu.edu\ndescription: \"TBA\"\ndate: 2022-12-13\ndraft: true\ncategories: [project 4, projects]\n---\n\n\n# Background\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n```\n:::\n\n\n\n**Due date: December 23 at 11:59pm**\n\nThe goal of this assignment is to practice building interactive web applications / dashboards, along with the data analytic tools you have learned in this course. \n\n### To submit your project\n\nCreate a public github repository for yourself. The link to create the repository will be in CoursePlus. \n\n### The set up\n\nImagine you are a data scientist at a company or nonprofit and you have been tasked analyze a data set and to build an interactive dashboard to share with stake holders in the company. \n\nThe set up is meant to be broad. You can think about any question / data you might be interested in exploring within this hypothetical scenario. \n\n# Part 1: Download the datasets\n\n## Part 1A\n\nPick a dataset from one of the following to use for your analysis: \n\n- [TidyTuesday](https://www.tidytuesday.com) or\n- An API (e.g. using `httr`)\n\nThis should be a dataset **that you have not worked with before** (i.e. not in a previous project or assignment from this class or from 776, but other classes or personal projects are acceptable). \n\n## Part 1B\n\nUsing `rvest`, scrape a dataset (e.g. from a table in an HTML). \n\nSpecifically, you will need to combine the dataset from Parts 1A and 1B in some way for your data analysis below. This must be more than some superficial combination and both parts should be important for the analysis and dashboard. \n\n## Part 1C\n\nSave the data locally to be able to loaded into R:\n\n  - In this step, you must test if a directory named `data` exists locally. If it does not, write an R function that creates it programmatically.  \n  - Saves the data only once (not each time you knit/render the document). \n  - Read in the data locally each time you knit/render. \n  \n\n\n# Part 2: Build a data analytic report\n\nBuild a data analytic report with the following sections:\n\n- **Motivation and Overview**: Provide an overview of the data analysis goals and the motivation for it.\n- **Related Work**: Anything that inspired you, such as a paper, a web site, or something we discussed in class.\n- **Data Analytic Questions**: What question(s) are you trying to answer with the data and data analysis? What new questions did you consider in the course of your analysis?\n- **Audience**: Who is the target audience for your analysis? Should they be expected to have a specific background or knowledge? \n- **Data**: What are the original data sources? Include a link to a data dictionary for the data or create one inside the analysis. \n- **Exploratory Data Analysis**: What visualizations did you use to look at your data in different ways? What are the different statistical methods you considered? Justify the decisions you made, and show any major changes to your ideas. How did you reach these conclusions? You should use this section to motivate the statistical analyses that you decided to use in the next section.\n  - You must use at least **ten different functions** from `dplyr`, `tidyr`, `lubridate`, `stringr`, `forcats`, or `purrr`. \n  - Your analysis should include at least three plots with you using at least three different `geom_*()` functions from `ggplot2` (or another package with `geom_*()` functions). \n    - Plots should have titles, subtitles, captions, and human-understandable axis labels. \n    - At least one plot should using a type of faceting (`facet_grid()` or `facet_wrap()`). \n- **Modeling or prediction**: Fit a statistical model (either for inference or prediction) with your data. What statistical or computational method did you apply and why? What others did you consider?\n- **Narrative and Summary**: What did you learn about the data? How did you answer the questions? How can you justify your answers? What are the key take aways for the audience? What are the limitations of the analyses?\n\nAt the end of the data analysis, list out each of the functions you used from each of the packages (`dplyr`, `tidyr`, `ggplot2`, etc) to help the TA with respect to making sure you met all the requirements described above. \n\n\n# Part 3: Build an interactive dashboard \n\nBuild an interactive dashboard (with a bunch of specific things e.g. 3 tabs, at least 3 interactive plots on different tabs, etc) from the data analysis\n\n- TBA\n- TBA\n- One of the tabs should be your data analysis with all of your code shown and code evaluted. \n\n# Part 4: Make a two minute video \n\nMake a two minute screencast with narration showing highlights of your data analysis and a demo of your interactive dashboard. Upload to YouTube or Vimeo and embed it into the dashboard in some way. \n\nUse principles of good storytelling and presentations to get your key points across. \n\n- Focus the majority of your screencast on your main contributions rather than on technical details. \n- What do you feel is the best part of your project? \n- What insights did you gain? \n- What is the single most important thing you would like your audience to take away? Make sure it is upfront and center rather than at the end.\n\n## Deploy dashboard and push code to Github \n\n- Using the public github repository, push your code to GitHub. Include a `README.md` file in the repository. \n- Deploy the website. This could be on shinyapps.io or another mechansim. \n- Share a link to your github repo with your code and your deployed interactive dashboard on CoursePlus. \n\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}